{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2620127",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31edc918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/nadhif/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in /Users/nadhif/anaconda3/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nadhif/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8138d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import string  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d4a21",
   "metadata": {},
   "source": [
    "## Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19069bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been scraped and saved to 'cost_of_living.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the Numbeo page you want to scrape\n",
    "url = 'https://www.numbeo.com/cost-of-living/rankings_by_country.jsp'\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the table containing cost of living data\n",
    "    table = soup.find('table', {'id': 't2'})\n",
    "\n",
    "    # Create empty lists to store data\n",
    "    categories = []\n",
    "    prices_usd = []\n",
    "    countries = []\n",
    "    cost_of_living_relative = []\n",
    "\n",
    "    # Iterate through rows in the table\n",
    "    for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "        columns = row.find_all('td')\n",
    "        categories.append(columns[1].text.strip())\n",
    "        prices_usd.append(columns[2].text.strip())\n",
    "        countries.append(columns[0].text.strip())\n",
    "        cost_of_living_relative.append(columns[3].text.strip())\n",
    "\n",
    "    # Create a DataFrame to store the data\n",
    "    data = {\n",
    "        'Country': countries,\n",
    "        'Product Category': categories,\n",
    "        'Price (USD)': prices_usd,\n",
    "        'Cost of Living Relative to US': cost_of_living_relative\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save the data to a CSV file\n",
    "    df.to_csv('cost_of_living.csv', index=False)\n",
    "\n",
    "    print(\"Data has been scraped and saved to 'cost_of_living.csv'.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve data from the website.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
